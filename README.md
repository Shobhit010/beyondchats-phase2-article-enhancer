 # Phase 2 â€” AI-Powered Article Enhancer & Publisher

 An orchestration script (Node.js) that enhances and republishes articles by finding top-ranking competitors, extracting content, improving the original with an LLM, and publishing the updated version via a CRUD API.

 ---

 ## ğŸ“Œ Objective

 For each article produced in Phase 1 the pipeline will:

 1. Fetch the article from your API
 2. Search the article title via Google Custom Search
 3. Identify top competing blog articles
 4. Scrape the real content from those articles
 5. Rewrite and improve the original using an LLM
 6. Append references to the source articles
 7. Publish the updated article via the CRUD API

 ---

 ## ğŸ§  High-Level Architecture

 Source API â†’ Google Custom Search â†’ External Articles â†’ Scraper â†’ LLM Rewrite â†’ Publish API

 ---

 ## âš ï¸ Difficulty & Considerations

- External API integrations (Google, OpenAI)
- Web scraping across heterogeneous HTML
- Prompt engineering and LLM output validation
- Rate limits and polite scraping (respect robots.txt)

 ---

 ## ğŸ›  Tech Stack

- Node.js â€” runtime
- axios â€” HTTP requests
- cheerio â€” HTML parsing / scraping
- Google Custom Search API â€” search queries
- OpenAI API (or other LLM provider) â€” rewriting
- dotenv â€” environment variables

 ---

 ## ğŸ“‚ Project Structure

 phase2-article-enhancer/

- index.js â€” pipeline entrypoint
- .env â€” environment variables (not committed)
- services/
  - fetchArticles.js â€” fetch articles from Phase 1 API
  - googleSearch.js â€” query Google Custom Search API
  - scrapeContent.js â€” scrape candidate articles
  - llmRewrite.js â€” orchestrate LLM rewrite
  - publishArticle.js â€” call CRUD API to update articles
- utils/
  - isArticleUrl.js â€” helper to validate article URLs

 ---

 ## âš™ï¸ Prerequisites

- Phase 1 backend (the source CRUD API) is available
- Node.js installed (recommended v16+)
- Create a `.env` file with the values below

 Example API endpoints used by the project:

```
GET  http://localhost:5000/api/articles
POST http://localhost:5000/api/articles
```

 ---

 ## ğŸ” Environment Variables

Create a `.env` file in the project root with:

```env
GOOGLE_API_KEY=your_google_api_key
GOOGLE_CX=your_search_engine_id
OPENAI_API_KEY=your_openai_api_key
API_BASE_URL=http://localhost:5000
```

Notes:
- Use the official Google Custom Search API â€” do NOT scrape Google search result pages.
- Keep API keys secret and out of source control.

 ---

 ## ğŸ” Core Workflow Overview

1. Fetch articles from the source API
2. Search each title (top N results) via Google Custom Search
3. Filter for article-like URLs (exclude YouTube, social, PDFs)
4. Choose best 1â€“2 competing articles
5. Scrape content with `cheerio` (best-effort selectors)
6. Provide scraped text as context to the LLM to rewrite the original
7. Append a `References` section with source URLs
8. Publish via the source CRUD API

 ---

 ## â–¶ï¸ Running the Script

Install dependencies and run:

```bash
npm install
node index.js
```

Each article is processed sequentially: fetched â†’ enhanced â†’ published.

 ---

 ## âœ… Completion Checklist (Phase 2)

- Fetch articles from API
- Google search via official API
- Extract top competing articles
- Scrape real content
- LLM-based rewriting
- Append reference citations
- Publish updated articles

 ---

 ## âš ï¸ Limitations & Future Enhancements

- Scraping is best-effort and site-dependent
- LLM output quality depends on prompt and model
- Google API usage limits may apply

Possible improvements:
- Retry and error-recovery
- Duplicate detection and plagiarism checks
- Rate limiting and exponential backoff
- Better extraction (Readability.js / heuristics)

 ---

 ## ğŸ‘¨â€ğŸ’» Author

Shobhit Poddar â€” Full Stack Developer | Backend & AI Integration

 ---

## ğŸ“„ License

This project is licensed under the MIT License.
# Phase 2 â€” AI-Powered Article Enhancer & Publisher

An advanced **Node.js orchestration script** that enhances existing articles by:
- Finding top-ranking competing articles on Google
- Scraping real content from external sources
- Using an LLM to rewrite and improve the article
- Automatically publishing the updated version via an existing CRUD API

This phase focuses on **search integration, web scraping, NLP, LLM orchestration, and automated publishing**.

---

## ğŸ“Œ Phase 2 Objective

For each article from Phase 1:

1. Fetch article from your API  
2. Search the article title on Google  
3. Identify top competing blog articles  
4. Scrape real content from those articles  
5. Rewrite the original article using an LLM  
6. Cite reference articles  
7. Publish the updated article back via CRUD API  

---

## ğŸ§  High-Level Architecture

Your API â†’ Google Search â†’ External Articles â†’ Scraping
â†“
LLM Rewrite
â†“
Publish Updated Article

yaml
Copy code

---

## âš ï¸ Difficulty Level

**Very Difficult**

This phase involves:
- External API integration (Google Search, OpenAI)
- Web scraping (non-uniform HTML)
- Prompt engineering
- LLM output handling
- End-to-end orchestration
- Publishing via REST APIs

---

## ğŸ›  Tech Stack

| Technology | Purpose |
|----------|--------|
| Node.js | Runtime |
| Axios | HTTP requests |
| Cheerio | Web scraping |
| Google Custom Search API | Safe Google search |
| OpenAI API | LLM-based rewriting |
| dotenv | Environment variables |

---

## ğŸ“‚ Project Structure

phase2-article-enhancer/
â”‚
â”œâ”€â”€ index.js
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ fetchArticles.js
â”‚ â”œâ”€â”€ googleSearch.js
â”‚ â”œâ”€â”€ scrapeContent.js
â”‚ â”œâ”€â”€ llmRewrite.js
â”‚ â””â”€â”€ publishArticle.js
â”‚
â””â”€â”€ utils/
â””â”€â”€ isArticleUrl.js

yaml
Copy code

---

## âš™ï¸ Prerequisites

- âœ… Phase 1 backend completed
- âœ… CRUD API available

Example API:
GET http://localhost:5000/api/articles
POST http://localhost:5000/api/articles

yaml
Copy code

---

## ğŸ” Environment Variables

Create a `.env` file:

```env
GOOGLE_API_KEY=your_google_api_key
GOOGLE_CX=your_search_engine_id
OPENAI_API_KEY=your_openai_key
ğŸ” Google Search Integration (Important)
âš ï¸ Do NOT scrape Google HTML directly

This project uses the official Google Custom Search API:

Prevents IP bans

Stable and compliant

Production-safe

ğŸ§© Core Functional Modules
1ï¸âƒ£ Fetch Articles (Phase 1 API)
js
Copy code
GET /api/articles
Used as the starting input for the enhancement pipeline.

2ï¸âƒ£ Google Search by Title
Searches article title

Retrieves top search results

Limited to 5 results for relevance

3ï¸âƒ£ Filter Non-Article URLs
Automatically removes:

YouTube

Social media

PDFs

Non-blog links

4ï¸âƒ£ Select Top 2 Competing Articles
Only the best two external articles are used to guide rewriting.

5ï¸âƒ£ Scrape Article Content
Primary selector: <article><p>

Fallback: generic <p>

Best-effort scraping (site HTML varies)

6ï¸âƒ£ LLM-Based Article Rewriting
The LLM is instructed to:

Preserve topic & intent

Improve structure and readability

Match tone of top-ranking articles

Avoid plagiarism

Output in Markdown format

7ï¸âƒ£ Automatic Reference Citation
References are appended automatically:

md
Copy code
## References
1. https://example.com/article1
2. https://example.com/article2
8ï¸âƒ£ Publish Updated Article
Updated article is published using the same CRUD API:

json
Copy code
{
  "title": "Original Title (Updated)",
  "content": "Rewritten content with references"
}
â–¶ï¸ Running the Script
bash
Copy code
node index.js
Each article is processed sequentially:

Fetched

Enhanced

Published

âœ… Phase 2 Completion Checklist
âœ” Fetch articles from API
âœ” Google search via official API
âœ” Extract top competing articles
âœ” Scrape real content
âœ” LLM-based rewriting
âœ” Reference citation
âœ” Publish updated articles

âš ï¸ Limitations & Notes
Web scraping is best-effort, not guaranteed

LLM output depends on prompt quality

Google API has usage limits

Not designed for high concurrency (by intent)

ğŸš€ Possible Enhancements
Retry & error recovery

Duplicate detection

Rate limiting

Parallel processing

Better content extraction (Readability.js)

SEO scoring

Plagiarism checking

ğŸ‘¨â€ğŸ’» Author
Shobhit Poddar
Full Stack Developer | Backend & AI Integration
Node.js â€¢ APIs â€¢ Scraping â€¢ LLM Orchestration

ğŸ“„ License
This project is licensed under the MIT License.

yaml
Copy code

---
